{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CBIR_01.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "lX9Znd7329uQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Content Based Image Recommendation\n",
        "\n",
        "Content Based Image Recommendation or CBIR is a new way of Search Engine which enables a user to Search for similar images over the network with the help of images directly. "
      ]
    },
    {
      "metadata": {
        "id": "Kpm-q49c7WPY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Clone the Github Repository to Google Colab along with the Dataset.**"
      ]
    },
    {
      "metadata": {
        "id": "fCqLlp7O7S2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "13aa240a-d536-4396-b270-d6edc2893a56"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/thegreatgupta/CBIR.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CBIR'...\n",
            "remote: Enumerating objects: 60178, done.\u001b[K\n",
            "remote: Counting objects: 100% (60178/60178), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60075/60075), done.\u001b[K\n",
            "remote: Total 60178 (delta 117), reused 60151 (delta 102), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (60178/60178), 159.38 MiB | 29.80 MiB/s, done.\n",
            "Resolving deltas: 100% (117/117), done.\n",
            "Checking out files: 100% (60219/60219), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eflXaVFj7_AF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0512eb7b-5300-4a3e-875d-05a918d535b3"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CBIR  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TAWwMCwf8DAX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef221b4e-98fb-40c1-c003-598fa9675f47"
      },
      "cell_type": "code",
      "source": [
        "cd CBIR"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CBIR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qD6Rs4ml8OQt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "cc01a77b-240b-4fb0-caaa-f707e4f5c395"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CBIR_01.ipynb\t     CBIR_Model_Weight_ep15.h5\tmodel_evaluation.py\n",
            "CBIR_Colab_01.ipynb  dataset\t\t\tmodel_trail.py\n",
            "CBIR_Colab_02.ipynb  json_model.json\t\tmodel_training.py\n",
            "CBIR_Colab_03.ipynb  LICENSE\t\t\tREADME.md\n",
            "CBIR_Colab_04.ipynb  model\t\t\tweight.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TNGA0lpX29uU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import Required Packages"
      ]
    },
    {
      "metadata": {
        "id": "20RWatEH29uV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "492582e1-11cf-4a98-c39f-fb8a87f37c83"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "from keras.layers import Dense,GlobalAveragePooling2D, Dropout\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, save_img\n",
        "from keras.models import Model, load_model\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "xV8885PBD69e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers, optimizers\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aZxX1IWQ29ue",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Step - 1 : Data Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "GZyWzT6U29uf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#BASE_PATH = 'F:/GIT/CBIR/'\n",
        "BASE_PATH = ''\n",
        "annotation = pd.read_csv(BASE_PATH + 'dataset/annotation.txt', delimiter='\\t') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tdB4BKJP29uh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "0a2af61a-1b2a-4862-87ae-51c9aa68dd68"
      },
      "cell_type": "code",
      "source": [
        "annotation.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>color</th>\n",
              "      <th>micro_category</th>\n",
              "      <th>macro_category</th>\n",
              "      <th>macro_category(english)</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "      <th>Unnamed: 6</th>\n",
              "      <th>Unnamed: 7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35154736FEF.jpg</td>\n",
              "      <td>BRONZO</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35157444XDF.jpg</td>\n",
              "      <td>PLATINO</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35157749QFF.jpg</td>\n",
              "      <td>NOCCIOLA</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35165506NDF.jpg</td>\n",
              "      <td>ORO</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35167181CRF.jpg</td>\n",
              "      <td>ANTRACITE</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          filename      color micro_category       macro_category  \\\n",
              "0  35154736FEF.jpg     BRONZO    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "1  35157444XDF.jpg    PLATINO    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "2  35157749QFF.jpg   NOCCIOLA    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "3  35165506NDF.jpg        ORO    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "4  35167181CRF.jpg  ANTRACITE    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "\n",
              "  macro_category(english)  Unnamed: 5  Unnamed: 6  Unnamed: 7  \n",
              "0                 leather         NaN         NaN         NaN  \n",
              "1                 leather         NaN         NaN         NaN  \n",
              "2                 leather         NaN         NaN         NaN  \n",
              "3                 leather         NaN         NaN         NaN  \n",
              "4                 leather         NaN         NaN         NaN  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "eQJCHigr29ul",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "c9f25524-f47b-4e99-a12a-a283504ce859"
      },
      "cell_type": "code",
      "source": [
        "annotation = annotation[['filename', 'color', 'micro_category', 'macro_category', 'macro_category(english)']]\n",
        "annotation.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>color</th>\n",
              "      <th>micro_category</th>\n",
              "      <th>macro_category</th>\n",
              "      <th>macro_category(english)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35154736FEF.jpg</td>\n",
              "      <td>BRONZO</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35157444XDF.jpg</td>\n",
              "      <td>PLATINO</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35157749QFF.jpg</td>\n",
              "      <td>NOCCIOLA</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35165506NDF.jpg</td>\n",
              "      <td>ORO</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35167181CRF.jpg</td>\n",
              "      <td>ANTRACITE</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          filename      color micro_category       macro_category  \\\n",
              "0  35154736FEF.jpg     BRONZO    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "1  35157444XDF.jpg    PLATINO    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "2  35157749QFF.jpg   NOCCIOLA    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "3  35165506NDF.jpg        ORO    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "4  35167181CRF.jpg  ANTRACITE    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "\n",
              "  macro_category(english)  \n",
              "0                 leather  \n",
              "1                 leather  \n",
              "2                 leather  \n",
              "3                 leather  \n",
              "4                 leather  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "w85_6N2z29up",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "15ab533d-b941-46f8-d263-c94029d06419"
      },
      "cell_type": "code",
      "source": [
        "data_category_01 = annotation[['filename', 'macro_category(english)']]\n",
        "data_category_01.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>macro_category(english)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35154736FEF.jpg</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35157444XDF.jpg</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35157749QFF.jpg</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35165506NDF.jpg</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35167181CRF.jpg</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          filename macro_category(english)\n",
              "0  35154736FEF.jpg                 leather\n",
              "1  35157444XDF.jpg                 leather\n",
              "2  35157749QFF.jpg                 leather\n",
              "3  35165506NDF.jpg                 leather\n",
              "4  35167181CRF.jpg                 leather"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "6V3o-4iD29us",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "62aee44d-a49e-46d3-c9ee-4599c0c06951"
      },
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for name, groups in data_category_01.groupby('macro_category(english)'):\n",
        "    print(name)\n",
        "    count += 1\n",
        "\n",
        "print(count)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accessories\n",
            "bags\n",
            "coats\n",
            "diaries\n",
            "dresses\n",
            "eye glasses\n",
            "fitness\n",
            "footwear\n",
            "furnishings\n",
            "furniture\n",
            "gift ideas\n",
            "jeans\n",
            "jewellery\n",
            "knitwear\n",
            "leather\n",
            "lighting\n",
            "nursing\n",
            "overalls\n",
            "pants\n",
            "pets\n",
            "sea & swimming pool\n",
            "shirts\n",
            "skirts\n",
            "sportswear\n",
            "suitcases\n",
            "suits\n",
            "tables & kitchen\n",
            "tailleur\n",
            "tech gadget\n",
            "textile\n",
            "top wear\n",
            "toys\n",
            "watches/clocks\n",
            "33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l7_1rpYG6m06",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "data_category_02 = data_category_01.iloc[:, 1].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FHWWo5x86q7_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60b4a7ea-11d3-47e3-c0a5-1dad8beb0762"
      },
      "cell_type": "code",
      "source": [
        "type(data_category_02)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "nRytnbnw6vFx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67c2581a-1c9b-4afc-8c3c-887519be0bac"
      },
      "cell_type": "code",
      "source": [
        "data_category_02.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60204,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "Lg7DsplW631l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "data_category_02 = data_category_02.reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3sQNXo5866l6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b841c6d-fc5e-43ab-c9a8-e035fce4127c"
      },
      "cell_type": "code",
      "source": [
        "data_category_02.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60204, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "QQp5YN-E4gW2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#ohe = OneHotEncoder(sparse=False, categorical_features = [0])\n",
        "ohe = OneHotEncoder(sparse=False)\n",
        "data_category_01_ohe = ohe.fit_transform(data_category_02)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DuaPZv397BWC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8d1532b-6868-4cd1-dac9-00d4c3f9593c"
      },
      "cell_type": "code",
      "source": [
        "data_category_01_ohe.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60204, 33)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "iL09fvqX7E_O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "031505e8-2f3e-438c-b0fb-e687eab9693c"
      },
      "cell_type": "code",
      "source": [
        "data_category_01_ohe[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "w2iBKTM37VhA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "0306ff0d-2378-4a3b-999e-dd22ba77f9e1"
      },
      "cell_type": "code",
      "source": [
        "ohe.get_feature_names()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['x0_accessories', 'x0_bags', 'x0_coats', 'x0_diaries',\n",
              "       'x0_dresses', 'x0_eye glasses', 'x0_fitness', 'x0_footwear',\n",
              "       'x0_furnishings', 'x0_furniture', 'x0_gift ideas', 'x0_jeans',\n",
              "       'x0_jewellery', 'x0_knitwear', 'x0_leather', 'x0_lighting',\n",
              "       'x0_nursing', 'x0_overalls', 'x0_pants', 'x0_pets',\n",
              "       'x0_sea & swimming pool', 'x0_shirts', 'x0_skirts',\n",
              "       'x0_sportswear', 'x0_suitcases', 'x0_suits', 'x0_tables & kitchen',\n",
              "       'x0_tailleur', 'x0_tech gadget', 'x0_textile', 'x0_top wear',\n",
              "       'x0_toys', 'x0_watches/clocks'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "FDgCL4R37jyi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc954024-0dd6-4254-ba7e-a85319b8b3cf"
      },
      "cell_type": "code",
      "source": [
        "ohe.inverse_transform(data_category_01_ohe[:1, :])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['leather']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "3btcSlvM29uw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###### Below Code is commented.\n",
        "It is used to convert the Dataset downloaded to required size and store in Local Directory.\n",
        "It is done to convert and store the whole dataset at Github. This is done totally bacause of Computation."
      ]
    },
    {
      "metadata": {
        "id": "x585qr7O29ux",
        "colab_type": "raw"
      },
      "cell_type": "markdown",
      "source": [
        "```\n",
        "i=0\n",
        "count = 0\n",
        "for filename in data_category_01.values:\n",
        "    try:\n",
        "        image_load_path = BASE_PATH + 'dataset/images/' + filename[0].split('.')[0] + '_resized.' + filename[0].split('.')[1]\n",
        "        img = img_to_array(load_img(image_load_path, target_size=(128, 128, 3)))\n",
        "        image_save_path = BASE_PATH + 'dataset/img_128_128/' + filename[0]\n",
        "        save_img(image_save_path, img)\n",
        "        i += 1\n",
        "        if i % 1000 == 0:\n",
        "            print(i)\n",
        "    except:\n",
        "        print('File Not Found ' + filename)\n",
        "        count += 1\n",
        "        \n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "uQVo3QbI29uy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_array = np.ndarray(shape=(len(data_category_01), 24, 24, 3), dtype=float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JcWQ6wNj29u0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "011cc661-824b-4fd5-b0ad-97c98e6baa7a"
      },
      "cell_type": "code",
      "source": [
        "i=0\n",
        "count = 0\n",
        "for filename in data_category_01.values:\n",
        "    try:\n",
        "        #image_load_path = 'dataset/images/' + filename[0].split('.')[0] + '_resized.' + filename[0].split('.')[1]\n",
        "        image_load_path = BASE_PATH + 'dataset/img_128_128/' + filename[0]\n",
        "        #print(image_load_path)\n",
        "        img = img_to_array(load_img(image_load_path, target_size=(24, 24, 3)))\n",
        "        img = img / 255\n",
        "        image_array[i] = img\n",
        "        #np.append(image_array, img)\n",
        "        i += 1\n",
        "        if i % 10000 == 0:\n",
        "            print(i)\n",
        "    except:\n",
        "        print('File Not Found ' + filename[0])\n",
        "        count += 1\n",
        "    \n",
        "print('Count:' + str(count))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "Count:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VvuHWy3j29u4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###### Split the Dataset into Train and Test Dataset and Save it into two different folders i.e. training_set and test_set"
      ]
    },
    {
      "metadata": {
        "id": "BnAbCbEM29u5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_array, data_category_01_ohe, test_size=0.15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Axt4Pjs129u8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_array.resize(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z8CVQ32PAX2j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59ff9faf-4caa-4f59-be36-9a1695259050"
      },
      "cell_type": "code",
      "source": [
        "image_array.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "JXbZYe3sh9II",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4ebc39f-5321-45a0-f5f8-eb320089095d"
      },
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51173, 33)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "qo3SJicdB-Dv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "aacde812-9d38-46f2-de70-73ae381cab91"
      },
      "cell_type": "code",
      "source": [
        "baseMapNum = 32\n",
        "weight_decay = 1e-4\n",
        "model = Sequential()\n",
        "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=X_train.shape[1:]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PwyLTxcoAbeK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M7xkDB9ABZmK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "#model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sHfmgIeaSlfx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(8*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BVvGTGP5DPVV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Flatten())\n",
        "#model.add(GlobalAveragePooling2D())\n",
        "#model.add(Dropout(0.6))\n",
        "#model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(33, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6xoL5wolDSeD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1350
        },
        "outputId": "296fef5a-d676-41e1-f972-19d2d9bdb75b"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 12, 12, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 12, 12, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 12, 12, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 12, 12, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 6, 6, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 6, 6, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 6, 6, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 6, 6, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 6, 6, 128)         295040    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               115300    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 33)                3333      \n",
            "=================================================================\n",
            "Total params: 999,177\n",
            "Trainable params: 997,513\n",
            "Non-trainable params: 1,664\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RQrao_njErfz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False\n",
        "    )\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i1jISGr2Fvhh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#training\n",
        "batch_size = 64\n",
        "epochs=10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-gxl5It0FwDH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "ae6870fc-78e7-4ab1-d4c2-4388581f9aae"
      },
      "cell_type": "code",
      "source": [
        "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "        optimizer=opt_rms,\n",
        "        metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),steps_per_epoch=X_train.shape[0] // batch_size,epochs=1*epochs,verbose=1,validation_data=(X_test,y_test))\n",
        "model.save_weights('CBIR_Model_Weight_ep10.h5')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "799/799 [==============================] - 701s 877ms/step - loss: 1.2487 - acc: 0.6194 - val_loss: 1.0304 - val_acc: 0.6797\n",
            "Epoch 2/10\n",
            "799/799 [==============================] - 706s 884ms/step - loss: 0.9659 - acc: 0.7103 - val_loss: 1.1955 - val_acc: 0.6508\n",
            "Epoch 3/10\n",
            "799/799 [==============================] - 687s 859ms/step - loss: 0.9125 - acc: 0.7292 - val_loss: 0.9589 - val_acc: 0.7139\n",
            "Epoch 4/10\n",
            "799/799 [==============================] - 698s 874ms/step - loss: 0.8898 - acc: 0.7383 - val_loss: 0.9060 - val_acc: 0.7441\n",
            "Epoch 5/10\n",
            "799/799 [==============================] - 698s 874ms/step - loss: 0.8775 - acc: 0.7474 - val_loss: 1.0185 - val_acc: 0.7038\n",
            "Epoch 6/10\n",
            "799/799 [==============================] - 690s 864ms/step - loss: 0.8683 - acc: 0.7523 - val_loss: 1.0614 - val_acc: 0.6977\n",
            "Epoch 7/10\n",
            "799/799 [==============================] - 687s 859ms/step - loss: 0.8583 - acc: 0.7572 - val_loss: 0.8605 - val_acc: 0.7479\n",
            "Epoch 8/10\n",
            "799/799 [==============================] - 693s 868ms/step - loss: 0.8557 - acc: 0.7571 - val_loss: 1.3838 - val_acc: 0.6287\n",
            "Epoch 9/10\n",
            "799/799 [==============================] - 700s 876ms/step - loss: 0.8527 - acc: 0.7627 - val_loss: 0.8645 - val_acc: 0.7639\n",
            "Epoch 10/10\n",
            "799/799 [==============================] - 698s 873ms/step - loss: 0.8566 - acc: 0.7633 - val_loss: 0.8490 - val_acc: 0.7687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zp_yTFi7GfhL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}