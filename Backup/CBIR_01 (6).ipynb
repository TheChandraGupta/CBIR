{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CBIR_01.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "lX9Znd7329uQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Content Based Image Recommendation\n",
        "\n",
        "Content Based Image Recommendation or CBIR is a new way of Search Engine which enables a user to Search for similar images over the network with the help of images directly. "
      ]
    },
    {
      "metadata": {
        "id": "Kpm-q49c7WPY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Clone the Github Repository to Google Colab along with the Dataset.**"
      ]
    },
    {
      "metadata": {
        "id": "fCqLlp7O7S2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "68986369-d502-4a05-c39e-badecec0432f"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/thegreatgupta/CBIR.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CBIR'...\n",
            "remote: Enumerating objects: 60178, done.\u001b[K\n",
            "remote: Counting objects: 100% (60178/60178), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60075/60075), done.\u001b[K\n",
            "remote: Total 60178 (delta 117), reused 60151 (delta 102), pack-reused 0\n",
            "Receiving objects: 100% (60178/60178), 159.38 MiB | 40.31 MiB/s, done.\n",
            "Resolving deltas: 100% (117/117), done.\n",
            "Checking out files: 100% (60219/60219), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eflXaVFj7_AF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0600e991-43ef-41a6-d60e-99dc68334b6d"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CBIR  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TAWwMCwf8DAX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18096a4d-b07e-4b87-d7d3-10f0ea3e82a9"
      },
      "cell_type": "code",
      "source": [
        "cd CBIR"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CBIR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qD6Rs4ml8OQt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "6eb2f889-5e20-4ffc-d7e4-155533f02972"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CBIR_01.ipynb\t     CBIR_Colab_04.ipynb  model\t\t       README.md\n",
            "CBIR_Colab_01.ipynb  dataset\t\t  model_evaluation.py  weight.h5\n",
            "CBIR_Colab_02.ipynb  json_model.json\t  model_trail.py\n",
            "CBIR_Colab_03.ipynb  LICENSE\t\t  model_training.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TNGA0lpX29uU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import Required Packages"
      ]
    },
    {
      "metadata": {
        "id": "20RWatEH29uV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7853bbe9-5a68-40a2-e878-082390e529fa"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "from keras.layers import Dense,GlobalAveragePooling2D, Dropout\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, save_img\n",
        "from keras.models import Model, load_model\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "xV8885PBD69e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers, optimizers\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aZxX1IWQ29ue",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Step - 1 : Data Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "GZyWzT6U29uf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#BASE_PATH = 'F:/GIT/CBIR/'\n",
        "BASE_PATH = ''\n",
        "annotation = pd.read_csv(BASE_PATH + 'dataset/annotation.txt', delimiter='\\t') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tdB4BKJP29uh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "7a6a41ab-dc3d-4d02-e251-087a0bac9eff"
      },
      "cell_type": "code",
      "source": [
        "annotation.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>color</th>\n",
              "      <th>micro_category</th>\n",
              "      <th>macro_category</th>\n",
              "      <th>macro_category(english)</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "      <th>Unnamed: 6</th>\n",
              "      <th>Unnamed: 7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35154736FEF.jpg</td>\n",
              "      <td>BRONZO</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35157444XDF.jpg</td>\n",
              "      <td>PLATINO</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35157749QFF.jpg</td>\n",
              "      <td>NOCCIOLA</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35165506NDF.jpg</td>\n",
              "      <td>ORO</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35167181CRF.jpg</td>\n",
              "      <td>ANTRACITE</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          filename      color micro_category       macro_category  \\\n",
              "0  35154736FEF.jpg     BRONZO    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "1  35157444XDF.jpg    PLATINO    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "2  35157749QFF.jpg   NOCCIOLA    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "3  35165506NDF.jpg        ORO    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "4  35167181CRF.jpg  ANTRACITE    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "\n",
              "  macro_category(english)  Unnamed: 5  Unnamed: 6  Unnamed: 7  \n",
              "0                 leather         NaN         NaN         NaN  \n",
              "1                 leather         NaN         NaN         NaN  \n",
              "2                 leather         NaN         NaN         NaN  \n",
              "3                 leather         NaN         NaN         NaN  \n",
              "4                 leather         NaN         NaN         NaN  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "eQJCHigr29ul",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "f3ec0cfa-5387-4241-ca76-14be950181a8"
      },
      "cell_type": "code",
      "source": [
        "annotation = annotation[['filename', 'color', 'micro_category', 'macro_category', 'macro_category(english)']]\n",
        "annotation.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>color</th>\n",
              "      <th>micro_category</th>\n",
              "      <th>macro_category</th>\n",
              "      <th>macro_category(english)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35154736FEF.jpg</td>\n",
              "      <td>BRONZO</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35157444XDF.jpg</td>\n",
              "      <td>PLATINO</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35157749QFF.jpg</td>\n",
              "      <td>NOCCIOLA</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35165506NDF.jpg</td>\n",
              "      <td>ORO</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35167181CRF.jpg</td>\n",
              "      <td>ANTRACITE</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          filename      color micro_category       macro_category  \\\n",
              "0  35154736FEF.jpg     BRONZO    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "1  35157444XDF.jpg    PLATINO    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "2  35157749QFF.jpg   NOCCIOLA    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "3  35165506NDF.jpg        ORO    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "4  35167181CRF.jpg  ANTRACITE    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "\n",
              "  macro_category(english)  \n",
              "0                 leather  \n",
              "1                 leather  \n",
              "2                 leather  \n",
              "3                 leather  \n",
              "4                 leather  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "w85_6N2z29up",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "691cca97-ef03-47df-8943-17dce0cdf67f"
      },
      "cell_type": "code",
      "source": [
        "data_category_01 = annotation[['filename', 'macro_category(english)']]\n",
        "data_category_01.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>macro_category(english)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35154736FEF.jpg</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35157444XDF.jpg</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35157749QFF.jpg</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35165506NDF.jpg</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35167181CRF.jpg</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          filename macro_category(english)\n",
              "0  35154736FEF.jpg                 leather\n",
              "1  35157444XDF.jpg                 leather\n",
              "2  35157749QFF.jpg                 leather\n",
              "3  35165506NDF.jpg                 leather\n",
              "4  35167181CRF.jpg                 leather"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "6V3o-4iD29us",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "559e3f36-e794-404d-c040-97ad664945e9"
      },
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for name, groups in data_category_01.groupby('macro_category(english)'):\n",
        "    print(name)\n",
        "    count += 1\n",
        "\n",
        "print(count)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accessories\n",
            "bags\n",
            "coats\n",
            "diaries\n",
            "dresses\n",
            "eye glasses\n",
            "fitness\n",
            "footwear\n",
            "furnishings\n",
            "furniture\n",
            "gift ideas\n",
            "jeans\n",
            "jewellery\n",
            "knitwear\n",
            "leather\n",
            "lighting\n",
            "nursing\n",
            "overalls\n",
            "pants\n",
            "pets\n",
            "sea & swimming pool\n",
            "shirts\n",
            "skirts\n",
            "sportswear\n",
            "suitcases\n",
            "suits\n",
            "tables & kitchen\n",
            "tailleur\n",
            "tech gadget\n",
            "textile\n",
            "top wear\n",
            "toys\n",
            "watches/clocks\n",
            "33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l7_1rpYG6m06",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "data_category_02 = data_category_01.iloc[:, 1].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FHWWo5x86q7_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b059038-3913-4945-d1cb-92713061f8f3"
      },
      "cell_type": "code",
      "source": [
        "type(data_category_02)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "nRytnbnw6vFx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a27a75fc-aa9a-491c-cbd4-e3b9c8f48585"
      },
      "cell_type": "code",
      "source": [
        "data_category_02.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60204,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "Lg7DsplW631l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "data_category_02 = data_category_02.reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3sQNXo5866l6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ed78cb0-d612-4fd3-9879-c3a18c95c646"
      },
      "cell_type": "code",
      "source": [
        "data_category_02.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60204, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "QQp5YN-E4gW2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#ohe = OneHotEncoder(sparse=False, categorical_features = [0])\n",
        "ohe = OneHotEncoder(sparse=False)\n",
        "data_category_01_ohe = ohe.fit_transform(data_category_02)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DuaPZv397BWC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d78dc42-e3e8-445e-bfac-2a2e753f4ef7"
      },
      "cell_type": "code",
      "source": [
        "data_category_01_ohe.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60204, 33)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "iL09fvqX7E_O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "21239573-9b2e-419b-a761-a6bd0014e944"
      },
      "cell_type": "code",
      "source": [
        "data_category_01_ohe[0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "w2iBKTM37VhA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "9aa09ab0-9d5f-4c67-98ac-6af2892874cf"
      },
      "cell_type": "code",
      "source": [
        "ohe.get_feature_names()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['x0_accessories', 'x0_bags', 'x0_coats', 'x0_diaries',\n",
              "       'x0_dresses', 'x0_eye glasses', 'x0_fitness', 'x0_footwear',\n",
              "       'x0_furnishings', 'x0_furniture', 'x0_gift ideas', 'x0_jeans',\n",
              "       'x0_jewellery', 'x0_knitwear', 'x0_leather', 'x0_lighting',\n",
              "       'x0_nursing', 'x0_overalls', 'x0_pants', 'x0_pets',\n",
              "       'x0_sea & swimming pool', 'x0_shirts', 'x0_skirts',\n",
              "       'x0_sportswear', 'x0_suitcases', 'x0_suits', 'x0_tables & kitchen',\n",
              "       'x0_tailleur', 'x0_tech gadget', 'x0_textile', 'x0_top wear',\n",
              "       'x0_toys', 'x0_watches/clocks'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "FDgCL4R37jyi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9c1e6e2-eefa-4dd8-ecc5-ce5b0f782990"
      },
      "cell_type": "code",
      "source": [
        "ohe.inverse_transform(data_category_01_ohe[:1, :])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['leather']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "3btcSlvM29uw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###### Below Code is commented.\n",
        "It is used to convert the Dataset downloaded to required size and store in Local Directory.\n",
        "It is done to convert and store the whole dataset at Github. This is done totally bacause of Computation."
      ]
    },
    {
      "metadata": {
        "id": "x585qr7O29ux",
        "colab_type": "raw"
      },
      "cell_type": "markdown",
      "source": [
        "```\n",
        "i=0\n",
        "count = 0\n",
        "for filename in data_category_01.values:\n",
        "    try:\n",
        "        image_load_path = BASE_PATH + 'dataset/images/' + filename[0].split('.')[0] + '_resized.' + filename[0].split('.')[1]\n",
        "        img = img_to_array(load_img(image_load_path, target_size=(128, 128, 3)))\n",
        "        image_save_path = BASE_PATH + 'dataset/img_128_128/' + filename[0]\n",
        "        save_img(image_save_path, img)\n",
        "        i += 1\n",
        "        if i % 1000 == 0:\n",
        "            print(i)\n",
        "    except:\n",
        "        print('File Not Found ' + filename)\n",
        "        count += 1\n",
        "        \n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "uQVo3QbI29uy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_array = np.ndarray(shape=(len(data_category_01), 24, 24, 3), dtype=float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JcWQ6wNj29u0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "71a26e57-9bc1-4788-e6b2-6cc61eb1e010"
      },
      "cell_type": "code",
      "source": [
        "i=0\n",
        "count = 0\n",
        "for filename in data_category_01.values:\n",
        "    try:\n",
        "        #image_load_path = 'dataset/images/' + filename[0].split('.')[0] + '_resized.' + filename[0].split('.')[1]\n",
        "        image_load_path = BASE_PATH + 'dataset/img_128_128/' + filename[0]\n",
        "        #print(image_load_path)\n",
        "        img = img_to_array(load_img(image_load_path, target_size=(24, 24, 3)))\n",
        "        img = img / 255\n",
        "        image_array[i] = img\n",
        "        #np.append(image_array, img)\n",
        "        i += 1\n",
        "        if i % 10000 == 0:\n",
        "            print(i)\n",
        "    except:\n",
        "        print('File Not Found ' + filename[0])\n",
        "        count += 1\n",
        "    \n",
        "print('Count:' + str(count))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "Count:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VvuHWy3j29u4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###### Split the Dataset into Train and Test Dataset and Save it into two different folders i.e. training_set and test_set"
      ]
    },
    {
      "metadata": {
        "id": "BnAbCbEM29u5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_array, data_category_01_ohe, test_size=0.15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Axt4Pjs129u8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_array.resize(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z8CVQ32PAX2j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "621883ff-75aa-4e28-dc4e-f119f455a178"
      },
      "cell_type": "code",
      "source": [
        "image_array.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "JXbZYe3sh9II",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cdca5373-8b99-404b-e3ba-019edab93d6a"
      },
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51173, 33)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "qo3SJicdB-Dv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "47709b6a-61bc-46f9-d6db-34aed60f4630"
      },
      "cell_type": "code",
      "source": [
        "baseMapNum = 32\n",
        "weight_decay = 1e-4\n",
        "model = Sequential()\n",
        "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=X_train.shape[1:]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PwyLTxcoAbeK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "txSfXlPo4V6A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "#model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M7xkDB9ABZmK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(8*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(8*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "#model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sHfmgIeaSlfx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(16*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(16*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.6))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BVvGTGP5DPVV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Flatten())\n",
        "#model.add(GlobalAveragePooling2D())\n",
        "#model.add(Dropout(0.6))\n",
        "#model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(33, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6xoL5wolDSeD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1598
        },
        "outputId": "471bb59d-42ef-498e-f45f-83a658eae077"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 12, 12, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 12, 12, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 12, 12, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 12, 12, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 6, 6, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 6, 6, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 6, 6, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 6, 6, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 6, 6, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 6, 6, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 6, 6, 512)         2048      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 6, 6, 512)         2048      \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               460900    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 33)                3333      \n",
            "=================================================================\n",
            "Total params: 5,184,393\n",
            "Trainable params: 5,180,425\n",
            "Non-trainable params: 3,968\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RQrao_njErfz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False\n",
        "    )\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i1jISGr2Fvhh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#training\n",
        "batch_size = 64\n",
        "epochs=10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-gxl5It0FwDH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "ae6870fc-78e7-4ab1-d4c2-4388581f9aae"
      },
      "cell_type": "code",
      "source": [
        "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "        optimizer=opt_rms,\n",
        "        metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),steps_per_epoch=X_train.shape[0] // batch_size,epochs=1*epochs,verbose=1,validation_data=(X_test,y_test))\n",
        "model.save_weights('CBIR_Model_Weight_ep10.h5')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "799/799 [==============================] - 701s 877ms/step - loss: 1.2487 - acc: 0.6194 - val_loss: 1.0304 - val_acc: 0.6797\n",
            "Epoch 2/10\n",
            "799/799 [==============================] - 706s 884ms/step - loss: 0.9659 - acc: 0.7103 - val_loss: 1.1955 - val_acc: 0.6508\n",
            "Epoch 3/10\n",
            "799/799 [==============================] - 687s 859ms/step - loss: 0.9125 - acc: 0.7292 - val_loss: 0.9589 - val_acc: 0.7139\n",
            "Epoch 4/10\n",
            "799/799 [==============================] - 698s 874ms/step - loss: 0.8898 - acc: 0.7383 - val_loss: 0.9060 - val_acc: 0.7441\n",
            "Epoch 5/10\n",
            "799/799 [==============================] - 698s 874ms/step - loss: 0.8775 - acc: 0.7474 - val_loss: 1.0185 - val_acc: 0.7038\n",
            "Epoch 6/10\n",
            "799/799 [==============================] - 690s 864ms/step - loss: 0.8683 - acc: 0.7523 - val_loss: 1.0614 - val_acc: 0.6977\n",
            "Epoch 7/10\n",
            "799/799 [==============================] - 687s 859ms/step - loss: 0.8583 - acc: 0.7572 - val_loss: 0.8605 - val_acc: 0.7479\n",
            "Epoch 8/10\n",
            "799/799 [==============================] - 693s 868ms/step - loss: 0.8557 - acc: 0.7571 - val_loss: 1.3838 - val_acc: 0.6287\n",
            "Epoch 9/10\n",
            "799/799 [==============================] - 700s 876ms/step - loss: 0.8527 - acc: 0.7627 - val_loss: 0.8645 - val_acc: 0.7639\n",
            "Epoch 10/10\n",
            "799/799 [==============================] - 698s 873ms/step - loss: 0.8566 - acc: 0.7633 - val_loss: 0.8490 - val_acc: 0.7687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zp_yTFi7GfhL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "f57bdf59-d77b-43a5-89df-4361ced639e4"
      },
      "cell_type": "code",
      "source": [
        "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "        optimizer=opt_rms,\n",
        "        metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),steps_per_epoch=X_train.shape[0] // batch_size,epochs=1*epochs,verbose=1,validation_data=(X_test,y_test))\n",
        "model.save_weights('CBIR_Model_Weight_ep10_02.h5')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "799/799 [==============================] - 29s 36ms/step - loss: 1.4598 - acc: 0.5700 - val_loss: 1.3328 - val_acc: 0.6345\n",
            "Epoch 2/10\n",
            "799/799 [==============================] - 23s 29ms/step - loss: 1.1106 - acc: 0.6699 - val_loss: 1.6624 - val_acc: 0.4923\n",
            "Epoch 3/10\n",
            "799/799 [==============================] - 23s 28ms/step - loss: 1.0737 - acc: 0.6895 - val_loss: 1.0264 - val_acc: 0.6925\n",
            "Epoch 4/10\n",
            "799/799 [==============================] - 23s 29ms/step - loss: 0.9901 - acc: 0.7174 - val_loss: 0.8958 - val_acc: 0.7441\n",
            "Epoch 5/10\n",
            "799/799 [==============================] - 23s 28ms/step - loss: 0.9464 - acc: 0.7317 - val_loss: 0.9120 - val_acc: 0.7533\n",
            "Epoch 6/10\n",
            "799/799 [==============================] - 23s 28ms/step - loss: 0.9128 - acc: 0.7423 - val_loss: 0.9322 - val_acc: 0.7320\n",
            "Epoch 7/10\n",
            "799/799 [==============================] - 23s 28ms/step - loss: 0.8902 - acc: 0.7525 - val_loss: 0.8121 - val_acc: 0.7732\n",
            "Epoch 8/10\n",
            "799/799 [==============================] - 23s 29ms/step - loss: 0.8680 - acc: 0.7573 - val_loss: 0.7738 - val_acc: 0.7841\n",
            "Epoch 9/10\n",
            "799/799 [==============================] - 23s 29ms/step - loss: 0.8561 - acc: 0.7614 - val_loss: 0.8938 - val_acc: 0.7318\n",
            "Epoch 10/10\n",
            "799/799 [==============================] - 23s 29ms/step - loss: 0.8471 - acc: 0.7674 - val_loss: 0.9550 - val_acc: 0.7413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mdbdAQNf7uyF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0VknO-2r9Bdy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = (model.predict(X_test) > 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fnYeq-FF8c3U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "outputId": "95a75b18-0c25-4886-e1cd-bad0dc33ca18"
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.07      0.13       252\n",
            "           1       0.86      0.65      0.74       150\n",
            "           2       0.83      0.41      0.55       779\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.91      0.96      0.94      1224\n",
            "           5       0.00      0.00      0.00        22\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       1.00      0.83      0.91      1383\n",
            "           8       0.00      0.00      0.00        19\n",
            "           9       0.00      0.00      0.00         3\n",
            "          10       0.00      0.00      0.00         3\n",
            "          11       0.88      0.21      0.34       256\n",
            "          12       1.00      0.04      0.07       234\n",
            "          13       0.93      0.13      0.23       874\n",
            "          14       0.84      0.23      0.37       111\n",
            "          15       0.00      0.00      0.00         6\n",
            "          16       0.00      0.00      0.00         2\n",
            "          17       0.00      0.00      0.00        31\n",
            "          18       0.79      0.82      0.80       898\n",
            "          19       0.00      0.00      0.00         8\n",
            "          20       0.00      0.00      0.00         0\n",
            "          21       0.83      0.48      0.61       676\n",
            "          22       0.87      0.86      0.87       488\n",
            "          23       0.00      0.00      0.00       159\n",
            "          24       0.00      0.00      0.00         8\n",
            "          25       0.00      0.00      0.00         6\n",
            "          26       0.00      0.00      0.00        28\n",
            "          27       0.00      0.00      0.00        15\n",
            "          28       0.00      0.00      0.00         9\n",
            "          29       0.00      0.00      0.00         1\n",
            "          30       0.83      0.70      0.76      1379\n",
            "          31       0.00      0.00      0.00         0\n",
            "          32       0.00      0.00      0.00         6\n",
            "\n",
            "   micro avg       0.88      0.60      0.71      9031\n",
            "   macro avg       0.34      0.19      0.22      9031\n",
            "weighted avg       0.84      0.60      0.65      9031\n",
            " samples avg       0.60      0.60      0.60      9031\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "y-IphJY651A-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "        optimizer=opt_rms,\n",
        "        metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),steps_per_epoch=X_train.shape[0] // batch_size,epochs=1*epochs,verbose=1,validation_data=(X_test,y_test))\n",
        "model.save_weights('CBIR_Model_Weight_ep10_02.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}