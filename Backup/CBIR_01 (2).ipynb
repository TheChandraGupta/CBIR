{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CBIR_01.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "lX9Znd7329uQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Content Based Image Recommendation\n",
        "\n",
        "Content Based Image Recommendation or CBIR is a new way of Search Engine which enables a user to Search for similar images over the network with the help of images directly. "
      ]
    },
    {
      "metadata": {
        "id": "Kpm-q49c7WPY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Clone the Github Repository to Google Colab along with the Dataset.**"
      ]
    },
    {
      "metadata": {
        "id": "fCqLlp7O7S2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "60fcd6d4-abc9-45f8-9dee-16c3ae08511c"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/thegreatgupta/CBIR.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CBIR'...\n",
            "remote: Enumerating objects: 60175, done.\u001b[K\n",
            "remote: Counting objects: 100% (60175/60175), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60072/60072), done.\u001b[K\n",
            "remote: Total 60175 (delta 115), reused 60151 (delta 102), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (60175/60175), 159.38 MiB | 27.74 MiB/s, done.\n",
            "Resolving deltas: 100% (115/115), done.\n",
            "Checking out files: 100% (60218/60218), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eflXaVFj7_AF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9bbddf1-3ca9-4ad3-f158-4734e6d4a688"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CBIR  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TAWwMCwf8DAX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c937ca4-d069-4402-f6e1-9c524f2712ab"
      },
      "cell_type": "code",
      "source": [
        "cd CBIR"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CBIR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qD6Rs4ml8OQt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "20783f86-77a8-41bc-9af2-7e0e4e7be706"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CBIR_01.ipynb\t     dataset\t      model_evaluation.py  weight.h5\n",
            "CBIR_Colab_01.ipynb  json_model.json  model_trail.py\n",
            "CBIR_Colab_02.ipynb  LICENSE\t      model_training.py\n",
            "CBIR_Colab_03.ipynb  model\t      README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TNGA0lpX29uU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import Required Packages"
      ]
    },
    {
      "metadata": {
        "id": "20RWatEH29uV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38dddfa4-593a-4dc1-8d7a-0c20e464ef7a"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "from keras.layers import Dense,GlobalAveragePooling2D, Dropout\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, save_img\n",
        "from keras.models import Model, load_model\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "xV8885PBD69e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers, optimizers\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aZxX1IWQ29ue",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Step - 1 : Data Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "GZyWzT6U29uf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#BASE_PATH = 'F:/GIT/CBIR/'\n",
        "BASE_PATH = ''\n",
        "annotation = pd.read_csv(BASE_PATH + 'dataset/annotation.txt', delimiter='\\t') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tdB4BKJP29uh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "5508bcb5-bd2f-4593-cf8f-ea28fed5909f"
      },
      "cell_type": "code",
      "source": [
        "annotation.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>color</th>\n",
              "      <th>micro_category</th>\n",
              "      <th>macro_category</th>\n",
              "      <th>macro_category(english)</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "      <th>Unnamed: 6</th>\n",
              "      <th>Unnamed: 7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35154736FEF.jpg</td>\n",
              "      <td>BRONZO</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35157444XDF.jpg</td>\n",
              "      <td>PLATINO</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35157749QFF.jpg</td>\n",
              "      <td>NOCCIOLA</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35165506NDF.jpg</td>\n",
              "      <td>ORO</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35167181CRF.jpg</td>\n",
              "      <td>ANTRACITE</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          filename      color micro_category       macro_category  \\\n",
              "0  35154736FEF.jpg     BRONZO    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "1  35157444XDF.jpg    PLATINO    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "2  35157749QFF.jpg   NOCCIOLA    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "3  35165506NDF.jpg        ORO    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "4  35167181CRF.jpg  ANTRACITE    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "\n",
              "  macro_category(english)  Unnamed: 5  Unnamed: 6  Unnamed: 7  \n",
              "0                 leather         NaN         NaN         NaN  \n",
              "1                 leather         NaN         NaN         NaN  \n",
              "2                 leather         NaN         NaN         NaN  \n",
              "3                 leather         NaN         NaN         NaN  \n",
              "4                 leather         NaN         NaN         NaN  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "eQJCHigr29ul",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "b6857a28-444a-4e8b-f5f2-130a981a2efd"
      },
      "cell_type": "code",
      "source": [
        "annotation = annotation[['filename', 'color', 'micro_category', 'macro_category', 'macro_category(english)']]\n",
        "annotation.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>color</th>\n",
              "      <th>micro_category</th>\n",
              "      <th>macro_category</th>\n",
              "      <th>macro_category(english)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35154736FEF.jpg</td>\n",
              "      <td>BRONZO</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35157444XDF.jpg</td>\n",
              "      <td>PLATINO</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35157749QFF.jpg</td>\n",
              "      <td>NOCCIOLA</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35165506NDF.jpg</td>\n",
              "      <td>ORO</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35167181CRF.jpg</td>\n",
              "      <td>ANTRACITE</td>\n",
              "      <td>GONNA PELLE</td>\n",
              "      <td>ABBIGLIAMENTO PELLE</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          filename      color micro_category       macro_category  \\\n",
              "0  35154736FEF.jpg     BRONZO    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "1  35157444XDF.jpg    PLATINO    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "2  35157749QFF.jpg   NOCCIOLA    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "3  35165506NDF.jpg        ORO    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "4  35167181CRF.jpg  ANTRACITE    GONNA PELLE  ABBIGLIAMENTO PELLE   \n",
              "\n",
              "  macro_category(english)  \n",
              "0                 leather  \n",
              "1                 leather  \n",
              "2                 leather  \n",
              "3                 leather  \n",
              "4                 leather  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "w85_6N2z29up",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "f1b77b9b-3849-4204-dd15-a576360b28b1"
      },
      "cell_type": "code",
      "source": [
        "data_category_01 = annotation[['filename', 'macro_category(english)']]\n",
        "data_category_01.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>macro_category(english)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35154736FEF.jpg</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35157444XDF.jpg</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35157749QFF.jpg</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35165506NDF.jpg</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35167181CRF.jpg</td>\n",
              "      <td>leather</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          filename macro_category(english)\n",
              "0  35154736FEF.jpg                 leather\n",
              "1  35157444XDF.jpg                 leather\n",
              "2  35157749QFF.jpg                 leather\n",
              "3  35165506NDF.jpg                 leather\n",
              "4  35167181CRF.jpg                 leather"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "6V3o-4iD29us",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "f885d0ce-97c0-432b-b093-1cfd29c5b06a"
      },
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for name, groups in data_category_01.groupby('macro_category(english)'):\n",
        "    print(name)\n",
        "    count += 1\n",
        "\n",
        "print(count)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accessories\n",
            "bags\n",
            "coats\n",
            "diaries\n",
            "dresses\n",
            "eye glasses\n",
            "fitness\n",
            "footwear\n",
            "furnishings\n",
            "furniture\n",
            "gift ideas\n",
            "jeans\n",
            "jewellery\n",
            "knitwear\n",
            "leather\n",
            "lighting\n",
            "nursing\n",
            "overalls\n",
            "pants\n",
            "pets\n",
            "sea & swimming pool\n",
            "shirts\n",
            "skirts\n",
            "sportswear\n",
            "suitcases\n",
            "suits\n",
            "tables & kitchen\n",
            "tailleur\n",
            "tech gadget\n",
            "textile\n",
            "top wear\n",
            "toys\n",
            "watches/clocks\n",
            "33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3btcSlvM29uw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###### Below Code is commented.\n",
        "It is used to convert the Dataset downloaded to required size and store in Local Directory.\n",
        "It is done to convert and store the whole dataset at Github. This is done totally bacause of Computation."
      ]
    },
    {
      "metadata": {
        "id": "x585qr7O29ux",
        "colab_type": "raw"
      },
      "cell_type": "markdown",
      "source": [
        "```\n",
        "i=0\n",
        "count = 0\n",
        "for filename in data_category_01.values:\n",
        "    try:\n",
        "        image_load_path = BASE_PATH + 'dataset/images/' + filename[0].split('.')[0] + '_resized.' + filename[0].split('.')[1]\n",
        "        img = img_to_array(load_img(image_load_path, target_size=(128, 128, 3)))\n",
        "        image_save_path = BASE_PATH + 'dataset/img_128_128/' + filename[0]\n",
        "        save_img(image_save_path, img)\n",
        "        i += 1\n",
        "        if i % 1000 == 0:\n",
        "            print(i)\n",
        "    except:\n",
        "        print('File Not Found ' + filename)\n",
        "        count += 1\n",
        "        \n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "uQVo3QbI29uy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_array = np.ndarray(shape=(len(data_category_01), 24, 24, 3), dtype=float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JcWQ6wNj29u0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1101
        },
        "outputId": "1ebc63d3-85ed-4fd5-8f62-3e20c68c8e9c"
      },
      "cell_type": "code",
      "source": [
        "i=0\n",
        "count = 0\n",
        "for filename in data_category_01.values:\n",
        "    try:\n",
        "        #image_load_path = 'dataset/images/' + filename[0].split('.')[0] + '_resized.' + filename[0].split('.')[1]\n",
        "        image_load_path = BASE_PATH + 'dataset/img_128_128/' + filename[0]\n",
        "        #print(image_load_path)\n",
        "        img = img_to_array(load_img(image_load_path, target_size=(24, 24, 3)))\n",
        "        img = img / 255\n",
        "        image_array[i] = img\n",
        "        #np.append(image_array, img)\n",
        "        i += 1\n",
        "        if i % 1000 == 0:\n",
        "            print(i)\n",
        "    except:\n",
        "        print('File Not Found ' + filename[0])\n",
        "        count += 1\n",
        "    \n",
        "print('Count:' + str(count))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n",
            "31000\n",
            "32000\n",
            "33000\n",
            "34000\n",
            "35000\n",
            "36000\n",
            "37000\n",
            "38000\n",
            "39000\n",
            "40000\n",
            "41000\n",
            "42000\n",
            "43000\n",
            "44000\n",
            "45000\n",
            "46000\n",
            "47000\n",
            "48000\n",
            "49000\n",
            "50000\n",
            "51000\n",
            "52000\n",
            "53000\n",
            "54000\n",
            "55000\n",
            "56000\n",
            "57000\n",
            "58000\n",
            "59000\n",
            "60000\n",
            "Count:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VvuHWy3j29u4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###### Split the Dataset into Train and Test Dataset and Save it into two different folders i.e. training_set and test_set"
      ]
    },
    {
      "metadata": {
        "id": "BnAbCbEM29u5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_array, data_category_01.iloc[:, 1], test_size=0.15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Axt4Pjs129u8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_array.resize(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z8CVQ32PAX2j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5d595ea-dfe3-499b-b88e-322d4f6ea993"
      },
      "cell_type": "code",
      "source": [
        "image_array.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "JXbZYe3sh9II",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "0f4cdcb2-a986-465f-9593-dff9802f0707"
      },
      "cell_type": "code",
      "source": [
        "data_category_01.iloc[:, -1].head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    leather\n",
              "1    leather\n",
              "2    leather\n",
              "3    leather\n",
              "4    leather\n",
              "Name: macro_category(english), dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "K2Gy_pmRQFaX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "769d1a71-b220-4f5b-fef9-76cfb838b212"
      },
      "cell_type": "code",
      "source": [
        "ohe = OneHotEncoder(sparse=False, categorical_features = [0])\n",
        "y_train = ohe.fit_transform(y_train).toarray()\n",
        "y_test = ohe.transform(y_test).toarray()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:392: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-45f8ea3964e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mohe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mohe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mohe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    514\u001b[0m             return _transform_selected(\n\u001b[1;32m    515\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_fit_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 self._categorical_features, copy=True)\n\u001b[0m\u001b[1;32m    517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/base.py\u001b[0m in \u001b[0;36m_transform_selected\u001b[0;34m(X, transform, dtype, selected, copy, retain_order)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mXt\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msparse\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \"\"\"\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretain_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '44358949TTF.jpg'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qo3SJicdB-Dv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "be02bb6c-24b1-4a76-d242-63f96dc92bf2"
      },
      "cell_type": "code",
      "source": [
        "baseMapNum = 32\n",
        "weight_decay = 1e-4\n",
        "model = Sequential()\n",
        "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=X_train.shape[1:]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PwyLTxcoAbeK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M7xkDB9ABZmK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BVvGTGP5DPVV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Flatten())\n",
        "model.add(Dense(33, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6xoL5wolDSeD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1065
        },
        "outputId": "17aaff2e-c477-4c02-a3e5-6974a85a6ee2"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 64, 64, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 64, 64, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 64, 64, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 64, 64, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 33)                270369    \n",
            "=================================================================\n",
            "Total params: 559,169\n",
            "Trainable params: 558,273\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RQrao_njErfz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False\n",
        "    )\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i1jISGr2Fvhh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#training\n",
        "batch_size = 32\n",
        "epochs=5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-gxl5It0FwDH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "        optimizer=opt_rms,\n",
        "        metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),steps_per_epoch=X_train.shape[0] // batch_size,epochs=3*epochs,verbose=1,validation_data=(X_test,y_test))\n",
        "model.save_weights('CBIR_Model_Weight_ep15.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zp_yTFi7GfhL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}